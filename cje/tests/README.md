# CJE Test Suite

Comprehensive test suite for the Causal Judge Evaluation framework.

## Running Tests

```bash
# Run all tests
poetry run pytest cje/tests/

# Run tests by category using markers
poetry run pytest -m unit          # Fast unit tests
poetry run pytest -m integration   # Integration tests
poetry run pytest -m "not slow"    # Exclude slow tests

# Run specific test modules
poetry run pytest cje/tests/test_analysis.py      # High-level analysis API
poetry run pytest cje/tests/test_cli.py           # CLI functionality
poetry run pytest cje/tests/test_dr_diagnostics.py # DR estimator diagnostics
```

## Test Organization

### Core Functionality
- `test_simple.py` - Basic judge calibration and CJE estimation
- `test_pipeline.py` - End-to-end pipeline with edge cases
- `test_integration.py` - Full workflow integration test
- `test_data_models.py` - Data model validation

### High-Level APIs
- `test_analysis.py` - Tests `analyze_dataset()` function with real Arena data
- `test_cli.py` - Command-line interface (analyze, validate commands)
- `test_export.py` - JSON/CSV export functionality

### Estimators & Calibration
- `test_dr_basic.py` - Doubly robust estimation basics
- `test_dr_diagnostics.py` - Diagnostics for all estimators (IPS, DR, TMLE, MRDR)
- `test_stacked_simcal.py` - Stacked SIMCal weight calibration
- `test_custom_outcome_model.py` - Custom outcome models for DR

### Utilities
- `test_fresh_draws.py` - Fresh draw loading and auto-discovery
- `test_teacher_forcing.py` - Chat format conversion and templates
- `test_validation.py` - Dataset validation logic
- `test_edge_cases.py` - Missing values, extreme weights, edge cases

### Documentation
- `test_documentation_examples.py` - Ensures all README/docs examples work

## Test Data

### Arena Sample Data (`data/arena_sample/`)
- **Real Arena 10K data subset**: 100 samples with 4 policies
- **dataset.jsonl**: Main dataset with judge scores and oracle labels
- **responses/**: Fresh draws for DR estimation
  - `clone_responses.jsonl`
  - `premium_responses.jsonl`
  - `parallel_universe_prompt_responses.jsonl`
  - `unhelpful_responses.jsonl`

### Synthetic Test Data (`data/`)
Generated by `create_test_data.py`:
- `basic_test_data.jsonl` - Simple data with all fields
- `missing_values_data.jsonl` - Data with missing log probs
- `extreme_weights_data.jsonl` - Edge cases for weight calculations
- `judge_calibration_data.jsonl` - Data with oracle labels for calibration
- `chat_data.jsonl` - Chat format examples

## Shared Fixtures (conftest.py)

Common fixtures available to all tests:
- `basic_dataset()` - Dataset with 20 samples and rewards
- `dataset_with_oracle()` - Dataset with 50% oracle label coverage
- `dataset_for_dr()` - Dataset with cross-validation folds
- `synthetic_fresh_draws()` - Mock fresh draws for DR testing

Helper functions:
- `create_test_samples()` - Factory for test data
- `assert_valid_estimation_result()` - Standard result validation
- `assert_weights_calibrated()` - Weight calibration checks
- `assert_dataset_valid()` - Dataset validation

## Test Coverage

- **102 tests** covering all major functionality
- **All estimators tested**: RawIPS, CalibratedIPS, DR-CPO, TMLE, MRDR, MRDR-TMLE
- **Real Arena data integration**: Tests use actual Arena 10K sample
- **Edge cases covered**: Missing values, extreme weights, empty datasets
- **CLI fully tested**: Parser, commands, error handling
- **Export formats tested**: JSON and CSV output validation

## Running Specific Scenarios

```bash
# Test with real Arena data only
poetry run pytest cje/tests/test_analysis.py -v

# Test all DR-related functionality
poetry run pytest cje/tests/test_dr*.py -v

# Quick smoke test
poetry run pytest cje/tests/test_simple.py -v

# Test without slow/API-dependent tests
poetry run pytest cje/tests/ -m "not slow"
```