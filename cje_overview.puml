@startuml
skinparam shadowing false
skinparam monochrome false
skinparam defaultTextAlignment left
skinparam Arrow { Color #6B7280 }
skinparam Rectangle { BorderColor #2F3A4A; RoundCorner 8; FontStyle bold }
skinparam note { BorderColor #A3A3A3; BackgroundColor #FCFCFC }

rectangle "Causal Judge Evaluation (CJE) â€” Engineering Overview" as TITLE #FFFFFF

' ---- Data (row 1) ----
rectangle "Logs\n(prompts, completions,\nlog-policy props l0)" as D_LOGS  #E9F2FF
rectangle "Judge scores S\n(LLM or human grader)"             as D_SCORES #E9F2FF
rectangle "Oracle slice\n(sampled & labeled)"                 as D_ORACLE #E9F2FF

D_LOGS -[hidden]-> D_SCORES
D_SCORES -[hidden]-> D_ORACLE

' ---- Calibrations (row 2) ----
rectangle "SIMCal (weights)\nSmooth & stabilize policy weights\n(monotone in S, mean-one,\nvariance-capped rho)" as C_SIM #EAF4EE
rectangle "Reward calibration\nLearn f(S) on oracle labels\n(mean-preserving map to R)" as C_RC #EAF4EE

C_SIM -[hidden]-> C_RC

' ---- Estimators (row 3) ----
rectangle "Cal-IPS\nWeighted average of calibrated rewards\nZhat = E_n[ W_cal * R ]" as E_IPS   #FFF4E5
rectangle "DR-CPO\nResiduals + predicted reward (doubly robust)\nZhat = E_n[ ghat_pi'(X) + W_cal*(R - mhat(X,A)) ]" as E_DRCPO #FFF4E5

E_IPS -[hidden]-> E_DRCPO

' ---- Outputs (row 4) ----
rectangle "Policy value\nV(pi') with confidence interval"  as O_VAL  #ECECEC
rectangle "Diagnostics\nESS, tail risk, overlap, judge drift" as O_DIAG #ECECEC

O_VAL -[hidden]-> O_DIAG

' ---- Flows ----
D_LOGS   --> C_SIM    : base policy weights
D_SCORES --> C_SIM    : index by S
D_SCORES --> C_RC     : scores S
D_ORACLE --> C_RC     : labels

C_SIM --> E_IPS       : W_cal
C_RC  --> E_IPS       : R = f(S)

C_SIM --> E_DRCPO     : W_cal
C_RC  --> E_DRCPO     : R = f(S)

E_IPS   --> O_VAL
E_DRCPO --> O_VAL
C_SIM   --> O_DIAG
E_IPS   --> O_DIAG
E_DRCPO --> O_DIAG

note right of C_SIM
Stabilizes importance weights:
- mean-one normalization
- monotone in judge score
- variance cap to avoid heavy tails
- optional targeting for IPS accuracy
end note

note right of E_DRCPO
Doubly robust: either the weights
or the reward model suffices for accuracy
(sqrt(n) inference under cross-fitting).
end note
@enduml
