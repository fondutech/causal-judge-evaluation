# Fresh Draws Workflow Plan

## Problem Statement

We've made `prompt_id` optional for logged data (auto-generated from prompt hash), but fresh draws still require explicit `prompt_id`. This creates a workflow gap where users must extract IDs from logged data before generating fresh draws.

## Design Principles

1. **Logged data is authoritative** - It defines the experimental setup and owns the prompt â†’ ID mapping
2. **Fresh draws are derivative** - They only have meaning in relation to logged data
3. **Explicit is better than implicit** - Dependencies should be clear
4. **Different contexts need different solutions** - Academic vs production vs experimentation

## Key Use Cases

### 1. Production Pipeline
- Logged data from production system
- Fresh draws generated by separate evaluation service
- Different teams may own different parts
- Need stable, explicit interfaces

### 2. Academic Research
- Logged data from initial experiment
- Fresh draws via API calls (OpenAI, Anthropic, etc.)
- May use different scripts/notebooks for generation
- Need reproducibility and clear data lineage

### 3. Quick Experimentation
- Just testing DR estimation
- May use synthetic fresh draws
- Want minimal friction
- Don't care about production robustness

## Proposed Solution

### Core Design: Keep the Asymmetry

1. **Logged data** continues to auto-generate IDs from prompt hash if not provided
2. **Fresh draws** continue to require explicit `prompt_id`
3. This reflects their different roles and maintains clear dependencies

### New Workflow Utilities

#### 1. Prompt Exporter
```python
# Export prompts with their IDs for external generation
export_prompts_for_fresh_generation(
    dataset: Dataset,
    output_path: str,
    format: str = "jsonl"  # or "csv", "json"
)

# Output format:
# {"prompt_id": "prompt_abc123", "prompt": "What is 2+2?", "policy": "premium"}
```

#### 2. Fresh Draw Generator Helper
```python
# For users who want to generate in Python
class FreshDrawGenerator:
    def __init__(self, logged_dataset: Dataset):
        self.logged_dataset = logged_dataset
        self.prompt_mapping = {s.prompt_id: s.prompt for s in logged_dataset.samples}
    
    def generate_batch(self, policy: str, api_client: Any) -> FreshDrawDataset:
        """Generate fresh draws maintaining alignment with logged data."""
        ...
```

#### 3. Fresh Draw Builder
```python
# For building fresh draws from external data
class FreshDrawBuilder:
    def __init__(self, logged_dataset: Dataset):
        self.logged_dataset = logged_dataset
        self.prompt_to_id = {s.prompt: s.prompt_id for s in logged_dataset.samples}
    
    def add_response(self, prompt: str, response: str, score: float):
        """Add a fresh draw, auto-mapping prompt to correct ID."""
        prompt_id = self.prompt_to_id.get(prompt)
        if not prompt_id:
            raise ValueError(f"Prompt not in logged dataset: {prompt}")
        ...
```

#### 4. Validation Enhancement
```python
# Enhanced validation with helpful error messages
def validate_fresh_draws_alignment(
    fresh_draws: FreshDrawDataset,
    logged_dataset: Dataset,
    policy: str,
    suggest_fixes: bool = True
) -> ValidationReport:
    """
    Returns detailed report with:
    - Missing prompt_ids
    - Extra prompt_ids
    - Suggested fixes (if prompt text matches but ID doesn't)
    """
    ...
```

## Implementation Plan

### Phase 1: Document Current Best Practice (Immediate)
- Add section to README about fresh draws workflow
- Show example of extracting prompts with IDs
- Explain why the asymmetry exists

### Phase 2: Basic Utilities (Week 1)
- Implement `export_prompts_for_fresh_generation()`
- Add example script for fresh draw generation
- Enhance validation error messages

### Phase 3: Advanced Helpers (Week 2)
- Implement `FreshDrawBuilder` for external data integration
- Add `FreshDrawGenerator` for API-based generation
- Create notebook examples

### Phase 4: Testing & Documentation (Week 3)
- Test with real workflows
- Get user feedback
- Refine based on actual usage

## What We're NOT Doing

1. **NOT adding prompt hashing to FreshDrawLoader** - This would hide dependencies
2. **NOT making fresh draws independent** - They're inherently dependent on logged data
3. **NOT auto-magically aligning** - Explicit coordination is better for production systems

## Benefits of This Approach

1. **Clear mental model** - Logged data is primary, fresh draws are secondary
2. **Flexible workflows** - Different utilities for different use cases
3. **Backward compatible** - Existing code continues to work
4. **Production ready** - Explicit dependencies, no hidden magic
5. **Debugging friendly** - Clear error messages when alignment fails

## Example Workflows

### Production Workflow
```python
# Step 1: Export prompts from logged data
logged = load_dataset_from_jsonl("production_logs.jsonl")
export_prompts_for_fresh_generation(logged, "prompts_with_ids.jsonl")

# Step 2: External system generates fresh draws using prompt_ids
# ... (separate service/script) ...

# Step 3: Load and validate
fresh = load_fresh_draws_from_jsonl("fresh_draws.jsonl")
validate_fresh_draws_alignment(fresh, logged, "premium")
```

### Research Workflow
```python
# All in one script
logged = load_dataset_from_jsonl("experiment.jsonl")
generator = FreshDrawGenerator(logged)
fresh = generator.generate_batch("gpt4", openai_client)
```

### Quick Experimentation
```python
# Just use synthetic
logged = load_dataset_from_jsonl("data.jsonl")
fresh = create_synthetic_fresh_draws(logged, "premium")
```

## Success Metrics

1. Users understand why they need to provide prompt_ids for fresh draws
2. Common workflows have convenient utilities
3. Error messages guide users to the right solution
4. No confusion about data dependencies

## Next Steps

1. Get feedback on this plan
2. Prioritize which utilities to build first
3. Start with documentation to set expectations
4. Build utilities based on actual user needs