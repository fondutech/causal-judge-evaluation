# Correct Data Usage for CJE Analysis

## Key Principle
**For importance sampling (IPS/SNIPS), use ONLY the P0 data file.** The target response files are for oracle evaluation only.

## Data Files and Their Purpose

### 1. `p0_scored_deterministic.jsonl` (PRIMARY FILE)
**Purpose**: Contains everything needed for importance sampling
- **What's in it**: P0's responses with judge scores and log probabilities
- **Key fields**:
  - `response`: The response generated by P0
  - `judge_score`: Judge's score for this response
  - `total_logprob`: log P(response | P0)
  - `target_logps`: Dictionary of {policy: log P(response | policy)}

**Usage**:
```python
# Importance weight for policy X
weight = exp(target_logps[X] - total_logprob)
```

### 2. `targets_scored_deterministic.jsonl` (ORACLE ONLY)
**Purpose**: Contains actual responses from each target policy for oracle evaluation
- **What's in it**: Each policy's own response with judge scores
- **Key fields**:
  - `policy`: Which policy generated this response
  - `response`: The response generated by that policy
  - `judge_score`: Judge's score for this response
- **NO log probabilities** - these aren't needed

**Usage**:
```python
# Oracle estimate = average score of policy's actual responses
oracle_score = mean([r.judge_score for r in targets if r.policy == "pi_cot"])
```

## Common Mistakes to Avoid

### ❌ Wrong: Trying to match responses between files
```python
# DON'T DO THIS
p0_response = p0_data[0]["response"]
pi_clone_response = find_matching_target_response("pi_clone")
# These are DIFFERENT responses due to temperature > 0
```

### ❌ Wrong: Looking for log probs in target file
```python
# DON'T DO THIS
target_record = load_target_record("pi_cot")
logprob = target_record["total_logprob"]  # This field doesn't exist!
```

### ✅ Correct: Use only P0 data for importance sampling
```python
# DO THIS
for record in p0_data:
    # Everything you need is here
    response = record["response"]
    reward = record["judge_score"]
    p0_logp = record["total_logprob"]
    
    for policy, target_logp in record["target_logps"].items():
        weight = exp(target_logp - p0_logp)
        # IPS estimate uses weight * reward
```

## Why This Design?

1. **Importance sampling requires**:
   - Samples from one policy (P0)
   - Rewards for those samples
   - Probability of those samples under all policies
   - All of this is in the P0 file

2. **Target responses are separate because**:
   - They're only needed for oracle/ground truth comparison
   - Including them in the main data would be confusing
   - They have different responses than P0 (temperature > 0)

3. **Log probabilities are computed once**:
   - Teacher forcing happens in Phase 1 (expensive)
   - Phase 2 just uses the precomputed values
   - No additional log prob computation in Phase 2

## Summary

- **For IPS/SNIPS**: Use `p0_scored_*.jsonl` only
- **For oracle comparison**: Use `targets_scored_*.jsonl`
- **Never**: Try to match responses between the two files
- **Remember**: All policies generate different responses due to sampling