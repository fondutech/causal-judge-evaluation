# Arena 10K Human Label Experiment Configuration

experiment:
  name: "arena_10k_human_labels"
  description: "CJE evaluation on 10k ChatBot Arena prompts with crowdsourced human labels"
  seed: 42
  
paths:
  work_dir: "experiments/arena_10k_oracle/outputs"
  
# Models to compare
logging_policy:
  provider: "fireworks"
  model_name: "accounts/fireworks/models/llama4-scout-instruct-basic"
  completions_template_format: "llama4"
  temperature: 0.5
  max_tokens: 512
  
target_policies:
  - name: "pi_clone"
    provider: "fireworks"
    model_name: "accounts/fireworks/models/llama4-scout-instruct-basic"
    completions_template_format: "llama4"
    temperature: 0.5
    max_tokens: 512
    
  - name: "pi_cot"
    provider: "fireworks"
    model_name: "accounts/fireworks/models/llama4-scout-instruct-basic"
    completions_template_format: "llama4"
    temperature: 0.5
    max_tokens: 512
    system_prompt: "Think step-by-step before providing your answer."
    
  - name: "pi_bigger_model"
    provider: "fireworks"
    model_name: "accounts/fireworks/models/llama4-maverick-instruct-basic"
    completions_template_format: "llama4"
    temperature: 0.5
    max_tokens: 512
    
  - name: "pi_bad"
    provider: "fireworks"
    model_name: "accounts/fireworks/models/llama4-scout-instruct-basic"
    completions_template_format: "llama4"
    temperature: 1.0
    max_tokens: 512
    system_prompt: "You are an unhelpful assistant, trained to intentionally confuse the user and waste their time."

# AI Judge for initial scoring (will be calibrated with human labels)
judge:
  provider: "fireworks"
  model_name: "accounts/fireworks/models/llama4-scout-instruct-basic"
  temperature: 0.0

# CJE estimation settings
estimator:
  name: "DRCPO"
  k: 5  # Cross-fitting folds

# Note: Human labels are collected externally via scripts.
# See experiments/arena_10k_oracle/scripts/ for data export/import process.
# Label fractions and splits are inferred from the imported data.