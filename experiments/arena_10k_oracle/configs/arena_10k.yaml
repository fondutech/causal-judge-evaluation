# Arena 10K Human Label Experiment Configuration

experiment:
  name: "arena_10k_human_labels"
  description: "CJE evaluation on 10k ChatBot Arena prompts with crowdsourced human labels"
  seed: 42
  
paths:
  work_dir: "experiments/arena_10k_oracle/outputs"
  
# Models to compare
logging_policy:
  provider: "fireworks"
  model_name: "accounts/fireworks/models/llama4-scout-instruct-basic"
  temperature: 0.5
  max_tokens: 1024
  
target_policies:
  - name: "pi_clone"
    provider: "fireworks"
    model_name: "accounts/fireworks/models/llama4-scout-instruct-basic"
    temperature: 0.5
    max_tokens: 1024
    
  - name: "pi_cot"
    provider: "fireworks"
    model_name: "accounts/fireworks/models/llama4-scout-instruct-basic"
    temperature: 0.5
    max_tokens: 1024
    system_prompt_suffix: "\n\nThink step-by-step before providing your answer."
    
  - name: "pi_bigger_model"
    provider: "fireworks"
    model_name: "accounts/fireworks/models/llama4-maverick-instruct-basic"
    temperature: 0.5
    max_tokens: 1024

# AI Judge for initial scoring (will be calibrated with human labels)
judge:
  provider: "fireworks"
  model_name: "accounts/fireworks/models/llama4-scout-instruct-basic"
  temperature: 0.0

# CJE estimation settings
estimator:
  name: "DRCPO"
  k: 5  # Cross-fitting folds

# Note: Human labels are collected externally via scripts.
# See experiments/arena_10k_oracle/scripts/ for data export/import process.
# Label fractions and splits are inferred from the imported data.