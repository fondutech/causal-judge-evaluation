{"prompt": "Judge test 0", "response": "Response to judge 0", "judge_score": 4.4842414298624735, "oracle_label": 0.30234713462929247, "total_logprob": -81.95302870591408, "target_logps": {"pi_test": -29.93494040416608}}
{"prompt": "Judge test 1", "response": "Response to judge 1", "judge_score": 0.18075363615520867, "oracle_label": 0.03990287236170782, "total_logprob": -34.56446005901128, "target_logps": {"pi_test": -41.63244162139232}}
{"prompt": "Judge test 2", "response": "Response to judge 2", "judge_score": 7.209399242521293, "oracle_label": 0.8196079357728321, "total_logprob": -33.68257176721133, "target_logps": {"pi_test": -35.8206633377225}}
{"prompt": "Judge test 3", "response": "Response to judge 3", "judge_score": 5.0881407683876, "oracle_label": 0.4516882420393338, "total_logprob": -38.91283162937848, "target_logps": {"pi_test": -66.58143825389575}}
{"prompt": "Judge test 4", "response": "Response to judge 4", "judge_score": 4.8674215295945515, "oracle_label": 0.5095424388497511, "total_logprob": -53.6551198250572, "target_logps": {"pi_test": -33.698582024805624}}
{"prompt": "Judge test 5", "response": "Response to judge 5", "judge_score": 3.500784076946757, "oracle_label": 0.31425566854308434, "total_logprob": -49.96333249017482, "target_logps": {"pi_test": -30.616054011910975}}
{"prompt": "Judge test 6", "response": "Response to judge 6", "judge_score": 4.991933798847523, "oracle_label": 0.5569882137066026, "total_logprob": -38.4864189468488, "target_logps": {"pi_test": -42.6340875581733}}
{"prompt": "Judge test 7", "response": "Response to judge 7", "judge_score": 0.4360377175443375, "oracle_label": 0.10767140722948494, "total_logprob": -33.27893616941185, "target_logps": {"pi_test": -49.49812696273511}}
{"prompt": "Judge test 8", "response": "Response to judge 8", "judge_score": 7.4771877389741395, "oracle_label": 0.8475515686330287, "total_logprob": -60.59137506949107, "target_logps": {"pi_test": -32.015980518234876}}
{"prompt": "Judge test 9", "response": "Response to judge 9", "judge_score": 5.527649668354899, "oracle_label": 0.6199677524305204, "total_logprob": -30.783359423664173, "target_logps": {"pi_test": -31.648468421126978}}
{"prompt": "Judge test 10", "response": "Response to judge 10", "judge_score": 1.9091103115034602, "oracle_label": null, "total_logprob": -33.12623687123812, "target_logps": {"pi_test": -34.641319712349926}}
{"prompt": "Judge test 11", "response": "Response to judge 11", "judge_score": 3.726868670940493, "oracle_label": null, "total_logprob": -56.595005631544886, "target_logps": {"pi_test": -28.730182454979804}}
{"prompt": "Judge test 12", "response": "Response to judge 12", "judge_score": 2.089187176153602, "oracle_label": null, "total_logprob": -41.12133844738675, "target_logps": {"pi_test": -32.441749306103176}}
{"prompt": "Judge test 13", "response": "Response to judge 13", "judge_score": 2.5416364906973876, "oracle_label": null, "total_logprob": -48.882910411309744, "target_logps": {"pi_test": -29.469019024921522}}
{"prompt": "Judge test 14", "response": "Response to judge 14", "judge_score": 7.089109969101186, "oracle_label": null, "total_logprob": -38.04794029221114, "target_logps": {"pi_test": -31.517018213629157}}
{"prompt": "Judge test 15", "response": "Response to judge 15", "judge_score": 4.197808564462765, "oracle_label": null, "total_logprob": -30.851159167646994, "target_logps": {"pi_test": -28.051983508176164}}
{"prompt": "Judge test 16", "response": "Response to judge 16", "judge_score": 6.27894414948636, "oracle_label": null, "total_logprob": -32.160114869469645, "target_logps": {"pi_test": -28.73582943697516}}
{"prompt": "Judge test 17", "response": "Response to judge 17", "judge_score": 3.967838272138884, "oracle_label": null, "total_logprob": -35.77097420412446, "target_logps": {"pi_test": -39.14821354550722}}
{"prompt": "Judge test 18", "response": "Response to judge 18", "judge_score": 3.2815266747473193, "oracle_label": null, "total_logprob": -31.6846790340319, "target_logps": {"pi_test": -68.08582822783548}}
{"prompt": "Judge test 19", "response": "Response to judge 19", "judge_score": 8.389335020693633, "oracle_label": null, "total_logprob": -30.39608912299421, "target_logps": {"pi_test": -31.613508800703265}}
{"prompt": "Judge test 20", "response": "Response to judge 20", "judge_score": 5.370824271966555, "oracle_label": null, "total_logprob": -33.95491869293684, "target_logps": {"pi_test": -45.594994861571635}}
{"prompt": "Judge test 21", "response": "Response to judge 21", "judge_score": 2.715429158197419, "oracle_label": null, "total_logprob": -48.45306301000318, "target_logps": {"pi_test": -30.161431538666225}}
{"prompt": "Judge test 22", "response": "Response to judge 22", "judge_score": 4.113539050566786, "oracle_label": null, "total_logprob": -42.02348160665083, "target_logps": {"pi_test": -29.4890971220987}}
{"prompt": "Judge test 23", "response": "Response to judge 23", "judge_score": 1.3274542224296981, "oracle_label": null, "total_logprob": -35.68314805681448, "target_logps": {"pi_test": -41.62744422592894}}
{"prompt": "Judge test 24", "response": "Response to judge 24", "judge_score": 2.508605273466612, "oracle_label": null, "total_logprob": -32.037499222681895, "target_logps": {"pi_test": -28.84330936165407}}
{"prompt": "Judge test 25", "response": "Response to judge 25", "judge_score": 4.283144749401078, "oracle_label": null, "total_logprob": -54.676216316763885, "target_logps": {"pi_test": -33.84027751991447}}
{"prompt": "Judge test 26", "response": "Response to judge 26", "judge_score": 2.397873591574032, "oracle_label": null, "total_logprob": -30.9857612629574, "target_logps": {"pi_test": -30.01952179343143}}
{"prompt": "Judge test 27", "response": "Response to judge 27", "judge_score": 9.346139973397097, "oracle_label": null, "total_logprob": -40.70349457388161, "target_logps": {"pi_test": -33.72121228716701}}
{"prompt": "Judge test 28", "response": "Response to judge 28", "judge_score": 7.3003931656181855, "oracle_label": null, "total_logprob": -30.488921034412943, "target_logps": {"pi_test": -36.34796487023098}}
{"prompt": "Judge test 29", "response": "Response to judge 29", "judge_score": 1.5864644764249103, "oracle_label": null, "total_logprob": -30.962896317055606, "target_logps": {"pi_test": -28.988892641878326}}
